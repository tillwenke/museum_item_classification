{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/till/projects/uni/data science/museum_item_classification/setup_general.py:92: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined_intermediate_ready = pd.read_csv('./data/general/combined_intermediate_ready.csv', index_col='id', dtype={'type': str})\n"
     ]
    }
   ],
   "source": [
    "from setup_general import *\n",
    "from setup_embedding import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_indicators = {}\n",
    "with open('data/type_indicators/type_ind_cut.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        a = line.split('\\'')\n",
    "        type = a[1]\n",
    "        indicators = a[2].split()\n",
    "        type_indicators[type] = indicators\n",
    "save_indicators = {}\n",
    "with open('data/type_indicators/save_indicator.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        a = line.split('\\'')\n",
    "        type = a[1]\n",
    "        indicators = a[2].split()\n",
    "        save_indicators[type] = indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive functions for type from text keywords\n",
    "\n",
    "def filtering(text):\n",
    "    pred = []\n",
    "    for type in types:            \n",
    "        if type in text:\n",
    "            pred.append(type)\n",
    "    if ('drawing' in text) or ('sketch' in text) or ('design' in text):\n",
    "        pred.append('design/drawing/sketch')\n",
    "    if len(pred) > 0:\n",
    "        return pred[-1]\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def indicating(text):\n",
    "    pred = []\n",
    "    for type in types:\n",
    "        for indicator in type_indicators[type]:\n",
    "            if indicator in text:\n",
    "                pred.append(type)\n",
    "    if len(pred) > 0:\n",
    "        return pred[-1]\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def save_indicating(text):\n",
    "    pred = []\n",
    "    for type in types:\n",
    "        if type in save_indicators.keys():\n",
    "            for indicator in save_indicators[type]:\n",
    "                if indicator in text:\n",
    "                    pred.append(type)\n",
    "    if len(pred) > 0:\n",
    "        return pred[-1]\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to numeric\n",
    "def replace_value(value: str):\n",
    "    if pd.isnull(value):\n",
    "        return value\n",
    "    return np.float64(value.replace(',', '.'))\n",
    "\n",
    "\n",
    "# convert to numeric and only keep year part\n",
    "def replace_start_end(value: str):\n",
    "    if pd.isnull(value):\n",
    "        return value\n",
    "    if re.match('^d?ddd$', value):\n",
    "        return int(value)\n",
    "    if re.match('dddd$', value):\n",
    "        return int(value[-4:])\n",
    "    elif not value[0].isdigit():\n",
    "        return int(f'19{value[-2:]}')\n",
    "    else:\n",
    "        return nan\n",
    "\n",
    "\n",
    "def extract_year_from_name(row):\n",
    "    name = row['name']\n",
    "    start = row['start']\n",
    "    if pd.isnull(start) and not pd.isnull(name):\n",
    "        match = re.search('\\d\\d\\d\\d', name)\n",
    "        if match:\n",
    "            start = match.group()\n",
    "    return start\n",
    "\n",
    "\n",
    "def preprocess_dataframe(df, submission=False):\n",
    "    categorical_cols = ['material', 'location', 'before_Christ', 'country_and_unit', 'technique', 'parameter',\n",
    "                        'museum_abbr', 'damages', 'state', 'color', 'event_type', 'collection_mark']\n",
    "    categorical_cols += ['unit', 'participants_role', 'participant', 'musealia_mark']\n",
    "\n",
    "    # just keeping track what values are used\n",
    "    numeric_cols = ['start', 'end', 'value', 'collection_queue_nr', 'is_original', 'ks', 'element_count',\n",
    "                    'musealia_seria_nr', 'musealia_queue_nr']\n",
    "\n",
    "    dropped_cols = ['id', 'parish']  # can't use\n",
    "    dropped_cols += ['full_nr', 'class', 'collection_additional_nr', 'additional_text', 'text', 'initial_info',\n",
    "                     'musealia_additional_nr']  # 'commentary','name', 'legend'\n",
    "\n",
    "    if not submission: dropped_cols.append('type')\n",
    "\n",
    "    df['start'] = df['start'].apply(replace_start_end)\n",
    "    df['end'] = df['end'].apply(replace_start_end)\n",
    "    df['value'] = df['value'].apply(replace_value)\n",
    "    df['start'] = df[['name', 'start']].apply(extract_year_from_name, axis=1)\n",
    "\n",
    "    df = df.drop(columns=dropped_cols)\n",
    "    df = pd.get_dummies(df, columns=categorical_cols)\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_label_from_comment(row):\n",
    "    # comment #################################################\n",
    "    comment = row['commentary']\n",
    "\n",
    "    if not pd.isnull(comment):\n",
    "        comment = str(comment).lower()\n",
    "\n",
    "        comment_dict = {\n",
    "            'lakk': 'pitser/templijäljend',\n",
    "            'must-valge negatiiv': 'fotonegatiiv',\n",
    "            'pitserilakk': 'pitser/templijäljend',\n",
    "            'käepide': 'pitsat',\n",
    "            'перф': 'fotonegatiiv',\n",
    "            'fotoemulsioon': 'fotomaterjal',\n",
    "            'plakat':'plakat'\n",
    "        }\n",
    "        for key, val in comment_dict.items():\n",
    "            if comment.startswith(key):\n",
    "                return val\n",
    "\n",
    "        if re.match('^\\d,\\d\\d\\sg$', comment):\n",
    "            return 'münt'\n",
    "\n",
    "        if 'diapositiiv' in comment:\n",
    "            return 'diapositiiv'\n",
    "\n",
    "    # name #################################################\n",
    "    name = row['name']\n",
    "\n",
    "    if not pd.isnull(name):\n",
    "        name = str(name).lower()\n",
    "        if name == ['denaar', 'killing', 'penn', 'schilling', '1/2 örtug', 'dirhem', 'fyrk']:\n",
    "            return 'münt'\n",
    "\n",
    "        for val in ['medal', 'plakat', 'märkmed', 'maal', 'kiri', 'kleit', 'kava', 'joonistus', 'graafika', 'dokument',\n",
    "                    'ajakiri', 'telegramm', 'skulptuur', 'raamat', 'postkaart', 'nukk', 'skulptuur', 'käsikiri']:\n",
    "            if name.startswith(val):\n",
    "                return val\n",
    "\n",
    "        name_dict = {\n",
    "            'kaustik': 'kaustik/vihik',\n",
    "            'vihik': 'kaustik/vihik',\n",
    "            'reprofoto': 'diapositiiv',\n",
    "        }\n",
    "        for key, val in name_dict.items():\n",
    "            if name.startswith(key):\n",
    "                return val\n",
    "    return nan\n",
    "\n",
    "\n",
    "def replace_predictions(labels, pred):\n",
    "    result = np.array(pred, copy=True)\n",
    "    for i, label in enumerate(labels):\n",
    "        if not pd.isnull(label) and label != 0:\n",
    "            result[i] = label\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine models via class-probability combination (soft-voting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the full ds used for submission?\n",
    "full = True\n",
    "# submit to \n",
    "name = 'red'\n",
    "sub_name = name + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/till/.local/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "#define models to be used for testing use 03 for submission use full\n",
    "import pickle\n",
    "xgb = XGBClassifier()\n",
    "xgb.load_model('models/xg/xg_est_data_smote100_03.json')\n",
    "\n",
    "rf = pickle.load(open('./models/rf/train_prep_full_best' , 'rb'))\n",
    "\n",
    "boost_emb = XGBClassifier()\n",
    "boost_emb.load_model('models/nlp/xgboost_03.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_est_prepared.copy() if full else val_est_prepared.copy()\n",
    "\n",
    "features = data.drop('type', axis=1)\n",
    "labels = data.type\n",
    "\n",
    "if not full:\n",
    "    # at least xgboost cannot deal with string labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder = label_encoder.fit(labels)\n",
    "    labels = label_encoder.transform(labels)\n",
    "    y_test = labels\n",
    "\n",
    "X_test = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['id'] = X_test.index\n",
    "results.set_index('id', inplace=True)\n",
    "if not full: results['type'] = y_test\n",
    "\n",
    "results['emb'] = [[-1]] * len(results)\n",
    "results['xg'] = [[-1]] * len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57665/1290882250.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['xg'].iloc[i] = np.array(item)\n"
     ]
    }
   ],
   "source": [
    "for i,item in enumerate(xgb.predict_proba(X_test)):\n",
    "    results['xg'].iloc[i] = np.array(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = test_curie.copy() if full else val_curie.copy()\n",
    "\n",
    "features = text.drop('type', axis=1)\n",
    "labels = text.type\n",
    "\n",
    "#text['pred'] = boost_emb.predict_proba(features)\n",
    "text['pred'] = [[-1]] * len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57665/2524059003.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text['pred'].iloc[i] = np.array(item)\n"
     ]
    }
   ],
   "source": [
    "for i,item in enumerate(boost_emb.predict_proba(features)):\n",
    "    text['pred'].iloc[i] = np.array(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, item in text.iterrows():\n",
    "        if index in results.index:\n",
    "            results.at[index, 'emb'] = item['pred']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evalaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "def vote(preds):\n",
    "    if preds[-1][0] == -1:\n",
    "        preds = preds[:-1]\n",
    "    res = np.sum(preds, axis=0)\n",
    "    return np.argmax(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['prediction'] = results.apply(lambda row: vote([row.xg, row.emb]), axis=1)\n",
    "if not full:\n",
    "    results.prediction = results.prediction.replace(type_lookup.id.to_list(), type_lookup.estonian.to_list())\n",
    "\n",
    "    a = results.prediction.copy().tolist()\n",
    "\n",
    "    df_submission = pd.read_csv(\"data/general/val.csv\")\n",
    "    x2 = preprocess_dataframe(df_submission, submission=True)\n",
    "    # reorder columns + add missing columns + remove extra columns\n",
    "    x2_labels = x2.apply(extract_label_from_comment, axis=1)    \n",
    "\n",
    "    results.prediction = replace_predictions(x2_labels, results.prediction)\n",
    "    submission = pd.DataFrame({'id': results.index ,'type': results.prediction})\n",
    "\n",
    "    b = results.prediction.copy().tolist()\n",
    "\n",
    "    count = 0\n",
    "    for i in range(len(a)):\n",
    "        if a[i] != b[i]:\n",
    "            count += 1\n",
    "            print(a[i], b[i])\n",
    "\n",
    "    print(count)\n",
    "\n",
    "    results.type = results.type.replace(type_lookup.id.to_list(), type_lookup.estonian.to_list())\n",
    "\n",
    "    print(accuracy_score(results.type, results.prediction))\n",
    "    print(classification_report(results.type, results.prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162 0.027\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def save_extract_label_from_comment(row):\n",
    "    name = row['name']\n",
    "\n",
    "    if not pd.isnull(name):\n",
    "        name = str(name).lower()\n",
    "        #'plakat', 'maal', 'kiri', 'dokument', 'kava', 'käsikiri', 'postkaart', 'raamat' (slightly off)\n",
    "\n",
    "        #'medal', 'märkmed', 'kleit', 'joonistus', 'graafika', 'skulptuur', 'nukk', 'telegramm', 'ajakiri' (correct)\n",
    "        for val in ['medal', 'märkmed', 'kleit', 'joonistus', 'graafika', 'skulptuur', 'nukk', 'telegramm', 'ajakiri']:\n",
    "            if name.startswith(val):\n",
    "                return val\n",
    "        \n",
    "\n",
    "        name_dict = {\n",
    "            'kaustik': 'kaustik/vihik',\n",
    "            'vihik': 'kaustik/vihik'\n",
    "        }\n",
    "        for key, val in name_dict.items():\n",
    "            if name.startswith(key):\n",
    "                return val\n",
    "    return nan\n",
    "\n",
    "if full:\n",
    "    results.prediction = results.prediction.replace(type_lookup.id.to_list(), type_lookup.estonian.to_list())\n",
    "    results = results.assign(prediction='not_predicted')\n",
    "    a = results.prediction.copy().tolist()\n",
    "\n",
    "    df_submission = pd.read_csv(\"data/general/test.csv\")\n",
    "    x2 = preprocess_dataframe(df_submission, submission=True)\n",
    "    # reorder columns + add missing columns + remove extra columns\n",
    "    x2_labels = x2.apply(save_extract_label_from_comment, axis=1)    \n",
    "\n",
    "    \n",
    "\n",
    "    results.prediction = replace_predictions(x2_labels, results.prediction)\n",
    "    submission = pd.DataFrame({'id': results.index ,'type': results.prediction})\n",
    "\n",
    "    b = results.prediction.copy().tolist()\n",
    "\n",
    "    count = 0\n",
    "    for i in range(len(a)):\n",
    "        if a[i] != b[i]:\n",
    "            count += 1\n",
    "            #print(a[i], b[i])\n",
    "\n",
    "    print(count, count/6000)\n",
    "\n",
    "\n",
    "    #submission.groupby('type').nunique()  # predicted classes\n",
    "\n",
    "    submission.to_csv(f'submissions/{sub_name}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004333333333333333"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.003 + 0.00566) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/6000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
