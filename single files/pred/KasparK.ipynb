{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "credits to Kaspar Kadalipp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from numpy import nan\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to numeric\n",
    "def replace_value(value: str):\n",
    "    if pd.isnull(value):\n",
    "        return value\n",
    "    return np.float64(value.replace(',', '.'))\n",
    "\n",
    "\n",
    "# convert to numeric and only keep year part\n",
    "def replace_start_end(value: str):\n",
    "    if pd.isnull(value):\n",
    "        return value\n",
    "    if re.match('^d?ddd$', value):\n",
    "        return int(value)\n",
    "    if re.match('dddd$', value):\n",
    "        return int(value[-4:])\n",
    "    elif not value[0].isdigit():\n",
    "        return int(f'19{value[-2:]}')\n",
    "    else:\n",
    "        return nan\n",
    "\n",
    "\n",
    "def extract_year_from_name(row):\n",
    "    name = row['name']\n",
    "    start = row['start']\n",
    "    if pd.isnull(start) and not pd.isnull(name):\n",
    "        match = re.search('\\d\\d\\d\\d', name)\n",
    "        if match:\n",
    "            start = match.group()\n",
    "    return start\n",
    "\n",
    "\n",
    "def preprocess_dataframe(df, submission=False):\n",
    "    categorical_cols = ['material', 'location', 'before_Christ', 'country_and_unit', 'technique', 'parameter',\n",
    "                        'museum_abbr', 'damages', 'state', 'color', 'event_type', 'collection_mark']\n",
    "    categorical_cols += ['unit', 'participants_role', 'participant', 'musealia_mark']\n",
    "\n",
    "    # just keeping track what values are used\n",
    "    numeric_cols = ['start', 'end', 'value', 'collection_queue_nr', 'is_original', 'ks', 'element_count',\n",
    "                    'musealia_seria_nr', 'musealia_queue_nr']\n",
    "\n",
    "    dropped_cols = ['id', 'parish']  # can't use\n",
    "    dropped_cols += ['full_nr', 'class', 'collection_additional_nr', 'additional_text', 'text', 'initial_info',\n",
    "                     'musealia_additional_nr']  # 'commentary','name', 'legend'\n",
    "\n",
    "    if not submission: dropped_cols.append('type')\n",
    "\n",
    "    df['start'] = df['start'].apply(replace_start_end)\n",
    "    df['end'] = df['end'].apply(replace_start_end)\n",
    "    df['value'] = df['value'].apply(replace_value)\n",
    "    df['start'] = df[['name', 'start']].apply(extract_year_from_name, axis=1)\n",
    "\n",
    "    df = df.drop(columns=dropped_cols)\n",
    "    df = pd.get_dummies(df, columns=categorical_cols)\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Extract labels from features: commentary, name, legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_label_from_comment(row):\n",
    "    # comment #################################################\n",
    "    comment = row['commentary']\n",
    "\n",
    "    if not pd.isnull(comment):\n",
    "        comment = str(comment).lower()\n",
    "\n",
    "        comment_dict = {\n",
    "            'lakk': 'pitser/templijäljend',\n",
    "            'must-valge negatiiv': 'fotonegatiiv',\n",
    "            'pitserilakk': 'pitser/templijäljend',\n",
    "            'käepide': 'pitsat',\n",
    "            'перф': 'fotonegatiiv',\n",
    "            'fotoemulsioon': 'fotomaterjal',\n",
    "            'plakat':'plakat'\n",
    "        }\n",
    "        for key, val in comment_dict.items():\n",
    "            if comment.startswith(key):\n",
    "                return val\n",
    "\n",
    "        if re.match('^\\d,\\d\\d\\sg$', comment):\n",
    "            return 'münt'\n",
    "\n",
    "        if 'diapositiiv' in comment:\n",
    "            return 'diapositiiv'\n",
    "\n",
    "    # name #################################################\n",
    "    name = row['name']\n",
    "\n",
    "    if not pd.isnull(name):\n",
    "        name = str(name).lower()\n",
    "        if name == ['denaar', 'killing', 'penn', 'schilling', '1/2 örtug', 'dirhem', 'fyrk']:\n",
    "            return 'münt'\n",
    "\n",
    "        for val in ['medal', 'plakat', 'märkmed', 'maal', 'kiri', 'kleit', 'kava', 'joonistus', 'graafika', 'dokument',\n",
    "                    'ajakiri', 'telegramm', 'skulptuur', 'raamat', 'postkaart', 'nukk', 'skulptuur', 'käsikiri']:\n",
    "            if name.startswith(val):\n",
    "                return val\n",
    "\n",
    "        name_dict = {\n",
    "            'kaustik': 'kaustik/vihik',\n",
    "            'vihik': 'kaustik/vihik',\n",
    "            'reprofoto': 'diapositiiv',\n",
    "        }\n",
    "        for key, val in name_dict.items():\n",
    "            if name.startswith(key):\n",
    "                return val\n",
    "    return nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/general/train.csv\")\n",
    "nlp_features = ['legend', 'name', 'commentary']\n",
    "\n",
    "# preprocess\n",
    "x = preprocess_dataframe(df)\n",
    "y = df[['type']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# extract labels\n",
    "labels = X_test.apply(extract_label_from_comment, axis=1)\n",
    "X_train = X_train.drop(columns=nlp_features)\n",
    "X_test = X_test.drop(columns=nlp_features)\n",
    "x = x.drop(columns=nlp_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF accuracy on validation data is: 0.8985714285714286\n",
      "New accuracy on validation data is: 0.9154761904761904\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "model = RandomForestClassifier(max_depth=800, n_estimators=200, random_state=0)\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "# validate\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'RF accuracy on validation data is: {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "def replace_predictions(labels, pred):\n",
    "    result = np.array(pred, copy=True)\n",
    "    for i, label in enumerate(labels):\n",
    "        if not pd.isnull(label) and label != 0:\n",
    "            result[i] = label\n",
    "    return result\n",
    "\n",
    "# accuracy with extracted labels\n",
    "y_pred_new = replace_predictions(labels, y_pred)  # more accurate data in comments\n",
    "print(f'New accuracy on validation data is: {accuracy_score(y_test, y_pred_new)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_submission = pd.read_csv(\"data/general/test.csv\")\n",
    "x2 = preprocess_dataframe(df_submission, submission=True)\n",
    "# reorder columns + add missing columns + remove extra columns\n",
    "x2_labels = x2.apply(extract_label_from_comment, axis=1)\n",
    "x2 = x2.reindex(columns=x2.columns).fillna(0)\n",
    "\n",
    "# best result\n",
    "#model = RandomForestClassifier(max_depth=800, n_estimators=200, random_state=0).fit(x, y.values.ravel())\n",
    "y_submission = model.predict(x2)\n",
    "y_submission = replace_predictions(x2_labels, y_submission)\n",
    "submission = pd.DataFrame({'id': df_submission['id'], 'type': y_submission})\n",
    "submission.groupby('type').nunique()  # predicted classes\n",
    "\n",
    "submission.to_csv('submissions/kaspar.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
