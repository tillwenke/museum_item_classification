{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_seq_items', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_bow(path, max_n_gram=2, max_features=2000):\n",
    "    dataset = pd.read_csv(path)\n",
    "\n",
    "    with open('data/general/estonian-stopwords.txt') as file:\n",
    "        lines = [line.rstrip() for line in file]\n",
    "    stopwords_est = lines\n",
    "    stop_words = stopwords_est\n",
    "\n",
    "    CountVec = TfidfVectorizer(ngram_range=(1,max_n_gram), stop_words=stop_words, max_features=max_features)\n",
    "    # to use bigrams ngram_range=(2,2)\n",
    "    Count_data = CountVec.fit_transform(dataset.text_features)\n",
    "    #create dataframe\n",
    "    bow=pd.DataFrame(Count_data.toarray(),columns=CountVec.get_feature_names_out())\n",
    "\n",
    "    bow = bow.add_prefix('word_')\n",
    "    bow.index = dataset.index\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/till/.local/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.3 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/till/.local/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.3 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/till/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aidu', 'bai', 'emb', 'emba', 'emma', 'emmaks', 'emmal', 'emmale', 'emmalt', 'emmas', 'emmasse', 'emmast', 'ha', 'he', 'heldeke', 'hii', 'hip', 'hoh', 'hä', 'hää', 'ih', 'ii', 'jaa', 'killa', 'kimps', 'kips', 'kirr', 'kirra', 'klu', 'kluu', 'kohva', 'kolla', 'kripa', 'krips', 'kõlk', 'kõlla', 'kõlladi', 'kõrra', 'köki', 'liiri', 'lika', 'likat', 'lutu', 'luutu', 'lõka', 'lõkat', 'lõõri', 'mull', 'mäta', 'möki', 'müh', 'müt', 'müta', 'ne', 'nämm', 'nõka', 'nõksat', 'nühkat', 'piiri', 'piu', 'pup', 'pääri', 'põrra', 'raidu', 'rips', 'sahka', 'sahkadi', 'setme', 'setmed', 'setmega', 'setmeid', 'setmeiks', 'setmeil', 'setmeile', 'setmeilt', 'setmeis', 'setmeisse', 'setmeist', 'setmeks', 'setmel', 'setmele', 'setmelt', 'setmena', 'setmeni', 'setmes', 'setmesse', 'setmest', 'setmeta', 'setmete', 'setmetega', 'setmeteks', 'setmetel', 'setmetele', 'setmetelt', 'setmetena', 'setmeteni', 'setmetes', 'setmetesse', 'setmetest', 'setmeteta', 'setu', 'setut', 'sihka', 'sihkadi', 'sihkat', 'silk', 'solk', 'suhkat', 'sulla', 'sulpa', 'summat', 'tall', 'talla', 'tap', 'tibi', 'tikk', 'tilla', 'tot', 'tutu', 'tuutu', 'vinki', 'vurra'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "dir = 'models/column/'\n",
    "models['column'] = pickle.load(file = open(dir + 'best_model_rfc_column_2023-03-24_13-50-23_0.6769557425091597.pkl', 'rb'))\n",
    "dir = 'models/text/'\n",
    "models['text'] = pickle.load(file = open(dir + 'best_model_rfc_text_2023-03-24_12-41-47_0.5694205848621395.pkl', 'rb'))\n",
    "\n",
    "\n",
    "data = {}\n",
    "data['column'] = pd.read_csv('data/inference/AM_ETMM_column.csv')\n",
    "data['text'] = text_to_bow(path='data/inference/AM_ETMM_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['id'] = data['column'].index\n",
    "results.set_index('id', inplace=True)\n",
    "\n",
    "for key, model in models.items():\n",
    "    results[key] = [-1] * len(results)\n",
    "\n",
    "results['safe'] = [-1] * len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "853\n",
      "853\n",
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "for key, model in models.items():\n",
    "    current_data = data[key]\n",
    "    print(len(model.feature_names_in_))\n",
    "    model_features = model.feature_names_in_\n",
    "    data_features = current_data.columns\n",
    "\n",
    "    # align features\n",
    "    model_not_data = [feature for feature in model_features if feature not in data_features]\n",
    "    current_data[model_not_data] = 0\n",
    "    intersection = [feature for feature in current_data.columns if feature in model_features]\n",
    "    current_data = current_data[intersection]\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
