{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_seq_items', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_bow(text_path, max_n_gram=2, max_features=2000):\n",
    "    dataset = pd.read_csv(text_path)\n",
    "    stop_words = stopwords_est\n",
    "\n",
    "    CountVec = TfidfVectorizer(ngram_range=(1,max_n_gram), stop_words=stop_words, max_features=max_features)\n",
    "    # to use bigrams ngram_range=(2,2)\n",
    "    Count_data = CountVec.fit_transform(dataset.text_features)\n",
    "    #create dataframe\n",
    "    bow=pd.DataFrame(Count_data.toarray(),columns=CountVec.get_feature_names_out())\n",
    "\n",
    "    bow = bow.add_prefix('word_')\n",
    "    bow.index = dataset.index\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "models = {}\n",
    "\n",
    "dir = 'models/column/'\n",
    "models['column'] = pickle.load(file = open(dir + 'best_model_rfc_column_2023-03-24_13-50-23_0.6769557425091597.pkl', 'rb'))\n",
    "dir = 'models/text/'\n",
    "models['text'] = pickle.load(file = open(dir + 'best_model_rfc_text_2023-03-24_12-41-47_0.5694205848621395.pkl', 'rb'))\n",
    "\n",
    "\n",
    "data = {}\n",
    "data['column'] = pd.read_csv('data/inference/AM_ETMM_column.csv')\n",
    "#data['text'] = pd.read_csv('data/inference/AM_ETMM_text.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['id'] = data.index\n",
    "results.set_index('id', inplace=True)\n",
    "\n",
    "for key, model in models.items():\n",
    "    results[key] = [-1] * len(results)\n",
    "\n",
    "results['safe'] = [-1] * len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "853\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/till/projects/uni/data science/museum_item_classification/inf.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/inf.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m key, model \u001b[39min\u001b[39;00m models\u001b[39m.\u001b[39mitems():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/inf.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     current_data \u001b[39m=\u001b[39m data[key]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/inf.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(model\u001b[39m.\u001b[39mfeature_names_in_))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/till/projects/uni/data%20science/museum_item_classification/inf.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     model_features \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfeature_names_in_\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "for key, model in models.items():\n",
    "    current_data = data[key]\n",
    "    print(len(model.feature_names_in_))\n",
    "    model_features = model.feature_names_in_\n",
    "    data_features = current_data.columns\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
